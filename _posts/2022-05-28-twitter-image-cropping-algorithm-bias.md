---
title: 트위터의 이미지 크롭 알고리즘은 뭐가 문제였을까
date: 2022-05-28 11:33:00 +09:00
categories:
  - Posts
  - Data
tags:
  - ai-in-society
math: true
toc: true
comments: true
image: /assets/img/posts/2022-05-28-twitter-image-cropping-algorithm-bias_8.png
---
> 트위터의 이미지 크롭 알고리즘을 둘러싼 인종차별 논란과 그 이후 트위터가 어떻게 대처했는지를 다룹니다. 자체 테스트와 알고리즘 편향 대회를 통해 발견된 내용들은 편리한 자동 크롭 기능이 어떤 의도치 않은 문제를 일으킬 수 있는지 보여줬습니다.
{: .prompt-info }

## 사건의 발단은

한 유저가 줌을 사용하면서 겪은 경험을 트위터에 공유하면서였습니다. 자신과 미팅을 한 상대방이 줌의 가상 배경 기능을 사용하자 자꾸 얼굴이 사라져서(즉 얼굴이 인식되지 않고 배경 처리되어) 불편을 겪었다는데요. 이 유저는 백인이었고, 얼굴 인식이 되지 않았던 사람은 흑인이었기 때문에 줌의 얼굴 인식 알고리즘이 흑인의 얼굴을 잘 인식하지 못하는 것이 아니냐는 문제제기를 한 것입니다. 

그런데 갑자기 줌이 아닌 트위터에 대한 비난으로 이야기가 바뀌기 시작합니다. 자신이 올린 두 명의 얼굴이 절반씩 온전히 다 나오는 사진들에서 매번 **백인인 자신의 얼굴만 크롭되어 나오는** 것을 발견한 것입니다.

[https://twitter.com/colinmadland/status/1307115534383710208?s=20&t=3lXZ_GcrqMPuDZ3ZP545Tw](https://twitter.com/colinmadland/status/1307115534383710208?s=20&t=3lXZ_GcrqMPuDZ3ZP545Tw)

![](/assets/img/posts/2022-05-28-twitter-image-cropping-algorithm-bias_1.png){:w="400"}


이 트윗들이 RT를 타고, 논란이 되고, 사람들이 비슷한 경험을 공유하거나 반박하기 시작하면서 주목을 받게 됩니다. 

이미지 크롭핑 알고리즘이 인종차별을 하고 있다는 지적을 받은 이후 트위터의 대응은 다음과 같습니다.

1. **자체적인 내부 조사**를 진행하고, 실제로 자사의 이미지 크롭 알고리즘이 편향적이라는 사실을 인정했습니다. 이 자체 테스트 결과는 페이퍼로 작성되어 공개되었습니다.
2. 해당 알고리즘에 대해 (자신들이 조사한 것 외의) **추가로 존재할 수 있는 편향을 밝히는 대회**를 열었습니다. 3명의 수상자가 최대 3500달러의 상금을 받아갔습니다.

처음 논의가 시작됐을 때 이 한 사람의 유저가 겪은 일이 단순히 한 번의 현상인지, 아니면 진짜 실제로 그런 문제가 존재하는 것인지가 엄청난 논쟁거리였죠. 저 스레드에 ‘내 폰에서는 그렇게 안 나오는데(백인 얼굴만 크롭되지 않는데)?’라고 답글을 단 사람들이 있었어요. 

과연 정확히 어떤 편향이 얼마나 있었고, 편향이 있다는 것을 규명하기 위해 어떤 방법을 사용했을까요? 이번 글에서는 트위터의 자체 조사 결과의 주요 발견들을 요약해보고, 그 이후 트위터가 주최한 알고리즘 편향 대회의 수상자들이 제시한 문제들도 한번 살펴보려고 합니다. 방법과 결과 자체도 흥미롭지만 이처럼 예기치 못한(그리고 의도치 않은) AI 관련 윤리적 문제가 발생했을 때 프로덕트 팀이 어떻게 대응해야 하는지도 잘 보여주는 사례라고 생각합니다.

## 일단 이미지 크롭 알고리즘이 뭐냐면

![](/assets/img/posts/2022-05-28-twitter-image-cropping-algorithm-bias_2.png)
_처음 트위터가 이미지 크롭 알고리즘을 도입했던 2018년 전후 대조. 도입 이후로 우리는 타임라인을 쓱슥 내리면서도 한번에 고영쓰 얼굴을 볼 수 있게 되었군 ([출처](https://www.dpreview.com/news/6095193348/twitter-is-using-ai-to-intelligently-crop-photos-around-the-eye-catching-bits))_

이미지 크롭은 업로드된 이미지를 그때그때 유저의 디바이스 화면 크기에 맞게 이미지를 잘라서 프리뷰를 보여주는 기능입니다. 우선 각 이미지의 가장 중요한 일부분만 자동으로 잘라서 보여주고, 더 자세히 보고 싶을 경우 클릭해서 보면 전체 이미지가 보이도록 작동하죠. 이렇게 하면 유저가 타임라인 내 넘쳐나는 이미지들을 일관된 크기로, 더 한눈에 빠르게 (중요한 부분만) 볼 수 있다는 장점이 있습니다. 


[2018년부터 사용해온 트위터의 이미지 크롭 알고리즘](https://arxiv.org/abs/1801.05787)은 각 이미지 구역의 saliency를 예측하도록 학습된 모델을 기반으로 합니다. saliency는 사람이 어떤 이미지를 볼 때 가장 시선이 가는 곳이 어느 부분인가? 즉 ‘눈에 띄는 정도’라고 생각하면 됩니다. 사람이나 특정 물체, 텍스트, 혹은 대조적인 배경 등이 이미지 내에서 가장 saliency가 높게 예측되면 그 부분을 위주로 보여주자! 가 이 모델이 수행하는 작업인 것입니다. 따라서 모델은 **이미지를 바라보는 사람의 시선을 일종의 정답지로 사용하여 훈련되며, 각 구역의 saliency score 를 계산한 후 가장 높은 점수를 가지는 부분을 크롭의 중심으로 사용**하게 됩니다.


![](/assets/img/posts/2022-05-28-twitter-image-cropping-algorithm-bias_3.jpeg)
_Saliency map의 예시_

## 정말 문제가 있었나? 트위터가 조사한 바에 따르면

조사 작업은 20년 가을 논쟁 이후 트위터의 META 팀에 의해서 진행되었습니다. 그 메타가 아니고 ML Ethics, Transparency and Accountability 팀이라고 합니다. (오…)

크게 문제로 지적되던 부분 및 이 페이퍼에서 중점으로 둔 사안은 다음 세 가지였는데요.

1. 중심부로 선택되는 비율의 인종 간 차이가 있다. 즉 백인 위주로 크롭된다.
2. 여성을 대상화하는 시선을 반영한다. 즉 여성의 몸과 얼굴이 다 나온 전신 사진에서 몸 위주로 크롭된다.
3. User agency가 없다. 즉 유저가 원하는 대로 이미지를 게시하지 못한다. 

하나하나 살펴봅시다.

### 이미지 크롭은 흑인보다 백인을, 남성보다 여성을 선호하고 있었다

편향이 정말 존재하는지 보려면 적합한 메트릭이 있어야 합니다. AI의 편향에 관한 연구들은 최근 몇 년 간 많이 진행되어 왔는데 아직까지 통일된 공통의 메트릭 같은 건 없는 상황입니다(앞으로도 계속 없을지도). 이번에 트위터가 사용한 것은 Demographic Parity 라는 개념으로, 제 생각에는 관련 문헌에 등장하는 것 중 가장 직관적이고 간단한 개념인 것 같습니다. **Demographic Parity는 인구 집단 별로 모델이 선호하는 비율이 차이가 나지만 않으면 편향이 없다고 봅니다**. 즉 지금 트위터에게 주어진 문제의 경우, 두 개의 인구 집단에서 각각 한 사람씩 뽑았을 때 그 둘의 얼굴 위주로 크롭될 가능성이 거의 같다면 우리 이미지 크롭 알고리즘 괜찮다! 문제 없다! 고 볼 수 있는 것입니다.

$$
\frac{P(R=1) \vert A=a)}{P(R=1) \vert A=b)} \le 1-\epsilon
$$

수식으로 쓰면 대충 이렇습니다. a, b가 각각 인구 집단이고(간단하게 흑인, 백인 아니면 남자, 여자) R=1이 그 사람이 가장 salient한 포인트로 속하는 사건이라고 보면 되겠군요. 그래서 두 개의 확률 차이가 거의 없어서 두 값을 나눈 값과 1의 차이가 epsilon이라는 아주 작은 값 이하로 떨어지면 오케이가 되겠습니다.

트위터는 Wikidata API를 사용해서 애매한 데이터는 빼고 명백히 자신들이 테스트하고 싶은 인구집단으로 구성된 셀럽들의 얼굴 사진 데이터셋을 사용했습니다. 흑인 여성 / 흑인 남성 / 백인 여성 / 백인 남성 이렇게 4가지 그룹이었고 사이즈는 각각 621개, 1348개, 213개, 606개였다고 하네요. 이 데이터를 가지고 랜덤하게 2개의 서로 다른 인종그룹에서 나온 2명을 수평으로 이어붙인 이미지를 만든 다음 기존의 이미지 크롭 알고리즘, 즉 saliency 예측 모델을 돌렸고, 둘 중  saliency score가 높아서 선택된 사람을 ‘모델이 선호했다’고 보았습니다. 이 실험을 10000번 반복함으로써 저 확률을 비교하게 됩니다.

![](/assets/img/posts/2022-05-28-twitter-image-cropping-algorithm-bias_4.png)

그 결과는 이렇습니다.

- 8%의 차이로 남성보다 여성을 선호
- 4%의 차이로 흑인보다 백인을 선호
- 7%의 차이로 흑인 여성보다 백인 여성을 선호
- 2%의 차이로 흑인 남성보다 백인 남성을 선호

즉 문제제기가 되었던 인종 간 차이는 (demographic parity라는 기준에 따르면) 분명히 존재했고, 의외로 그것보다 더 크게 성별 간 차이가 존재했다는 것이 테스트 결과였습니다.

### 여성의 몸을 더 많이 크롭한다는 증거는 찾지 못했다

이 논란은 위 인종차별 논란이 불거지면서 함께 딸려나온 주장 중 하나였습니다. 여성의 전신이 나온 사진에서 크롭 알고리즘이 여성의 얼굴이 아닌 몸을 크롭하여 여성을 대상화하는 male gaze를 반영한다는 주장인데요.

![](/assets/img/posts/2022-05-28-twitter-image-cropping-algorithm-bias_5.jpg)
_설명보다는 이미지로, 이런 상황입니다. ([출처](https://vinayprabhu.github.io/Saliency_Image_Cropping/))_

이 논란도 조사대상이 되었습니다. 이번에도 트위터는 계속 랜덤하게 100개의 남성과 여성의 사진을 골라서 모델의 선택을 확인했습니다(앞에서 한 것과 유사한 방식이죠). 이때는 앞선 결과와 달리 **특정 성별에서 얼굴보다 몸을 크롭하는 유의미한 비율 차이를 확인하지 못했다**고 합니다.

사람이 등장하는 이미지라면 평균적으로 100개 중 3개 정도만 얼굴이 아닌 몸이 saliency가 높아 선택되었고, 이 케이스를 살펴보면 대부분 몸이긴 하지만 신체와 관련 없는 이미지의 특정 부분이 눈에 띄는 경우였다는데요. 음 몸인데 신체랑 관련 없다는 게 뭔 소리냐면…

![](/assets/img/posts/2022-05-28-twitter-image-cropping-algorithm-bias_6.png)
이런 경우(선수 번호)라고 합니다. 이거밖에 언급이 없어서 다른 예시는 뭐가 있었는지 궁금하네요.

### 유저에게 선택권을 줘야 할까? 그래서 앞으로는

특정 인구 집단이 표현되는 방식에 영향을 준다는 것 외에도 자동 크롭의 문제점은 유저의 자율성을 침해한다는 것입니다. 자신이 게시하는 사진이 다른 사람들에게 어떻게 보일지에 대해 유저가 스스로 결정할 수 없는 상황인 거죠. 트위터는 테스트 결과를 통해 해당 알고리즘이 가져올 수 있는 문제와 자동 이미지 크롭의 편리함 간의 트레이드오프를 고민했고, **결국 알고리즘의 사용을 중단하고 이미지를 어떻게 크롭할지는 사람의 결정에 맡기는 것이 맞다**는 결론을 내리게 됩니다. 따라서 자동 크롭 없이 하나의 고정된 비율로 타임라인에 이미지를 게시할 수 있도록 했고, 게시하기 전에 유저가 사진이 어떻게 보일지 확인할 수 있도록 합니다.

[https://twitter.com/dantley/status/1390040111228723200?s=20&t=rZiI_lJ6vy_YTDQ8TbGrMg](https://twitter.com/dantley/status/1390040111228723200?s=20&t=rZiI_lJ6vy_YTDQ8TbGrMg)

<br>

## 다른 편향도 있는지 찾아주면 $3,500

여기서 그치지 않고 2021년에 트위터는 이 주제로 [상금을 건 대회](https://blog.twitter.com/engineering/en_us/topics/insights/2021/algorithmic-bias-bounty-challenge)를 개최합니다. **자신들이 발견한 부분 외의 다른 문제점을 찾아달라**는 것이 대회의 목적이었는데요. 대회 참여자들에게 이미지 크롭 알고리즘의 코드를 공개하고, 참가자들에게 자신만의 기준으로 편향을 규정하고 평가해달라고 요구했습니다. 3등까지 순위를 평가했고, 순서대로 3500, 1000, 500달러의 상금을 걸었습니다. 이 대회를 개최하면서 트위터는 이를 통해 알고리즘이 유발할 수 있으나 아직 대중에게 공개되지 않은 문제를 실천적이고 집단적으로 규명하는 선례를 자사뿐 아니라 업계 전체에 남기고 싶다고 밝혔습니다.

> 당시 공개된 트위터의 이미지 크롭핑 알고리즘 코드는 [여기](https://github.com/twitter-research/image-crop-analysis)서 찾아볼 수 있습니다.
{: .prompt-tip}

###  [How to Become More Salient? Surfacing Representation Biases of the Saliency Prediction Model](https://github.com/bogdan-kulynych/saliency_bias)


1위를 한 참가자는 StyleGAN2를 사용해서 counterfactual하게 얼굴 이미지를 변형해가면서 테스트하는 방식을 이용했습니다. counterfactual한 접근을 간단히 설명하면 다른 건 다 똑같고 이것만 달라졌는데 결과가 달라지면 이것이 원인이지 않을까? 라는 접근이라고 보시면 됩니다. 따라서 이 참가자는 다른 건 다 동일한 이미지를 살짝 더 젊은 얼굴로, 더 마른 얼굴로, 더 여성스러운 얼굴로, 흰머리가 없는 얼굴로 바꾸면서 saliency score가 어떻게 달라지는지 본 것이죠. 그 결과 **밝은 피부색, 어림, 여성, 마름에 대한 모델의 선호**를 확인할 수 있었다고 합니다.

![](/assets/img/posts/2022-05-28-twitter-image-cropping-algorithm-bias_7.png)
_이미지 변형과 saliency 증가의 예시_

### [HALT Saliency Algorithm Bias Evaluation of Group Photos](https://github.com/erickmu1/Twitter-Algorithmic-Bias)


2위 참가자는 다양한 모습의 사람들이 등장하는 데이터셋을 활용해서 하얀 머리색깔이나 알비노인 사람들이 그렇지 않은 사람보다 saliency가 높은 사람으로 선정될 확률이 떨어지는 점, 휠체어를 탄 장애를 가진 사람들이 공간적인 배치 때문에 크롭에서 제외될 수 있는 점 등을 밝혔습니다.


### [Gazing at the Mother Tongue: Analyzing Twitter's Image Cropping Algorithm on Bilingual Memes](https://github.com/royapakzad/image-crop-analysis)


마지막으로 3위 참가자는 밈 이미지에 삽입된 언어에 대한 모델의 선호를 들여다봤습니다. 지금까지 모든 접근이 인물 사진에만 초점을 맞추고 있었는데, 온갖 짤들이 범람하는 소셜 미디어에서 이 접근 또한 상당히 중요한 지적이라고 생각합니다. 비교 결과에 따르면 **모델이 동일한 밈에 대해서도 아랍어보다 영어에 대한 선호**를 보여줬다고 합니다. 


![](/assets/img/posts/2022-05-28-twitter-image-cropping-algorithm-bias_8.png){:w="550"}
_이런 식으로 붙여서 실험하면 크롭 알고리즘은 90%이상의 확률로 영어 짤만 보여준다고_


1~3위 외에도 소소하게 가장 신선한 접근과 가장 일반화하기 좋은 접근을 선정하기도 했는데요. 전자는 모델이 더 밝은 피부색을 가진 이모지(🤵🏾‍♀️<<<🤵🏼‍♀️)를 선호한다는 것을 밝힌 참가자였고, 후자는 이미지에 패딩을 붙여 크롭을 피할 수 있는 방법을 제시한 참가자였다고 합니다.

<br>

## 마치며

AI 알고리즘을 프로덕트에 적용할 때 발생할 수 있는 윤리적인 문제란 보통 의도한 것은 아닙니다. 아무도 백인의 얼굴 위주로 보여달라고 모델을 학습시키지는 않습니다. 그래서 문제는 항상 예기치 못하게 발생하죠. 중요한 것은 문제가 발생했을 때 어떻게 대응하느냐인데 트위터는 상당히 잘 대처했던 것 같습니다. 

특히 한 차례 조사에서 끝나지 않고 아예 대회를 개최해버린 것도 흥미로운 부분이었는데요. 대회 전후로 트위터의 이미지 크롭은 인종차별을 한다, 어리고 마른 여자를 선호한다는 식의 헤드라인으로 잔뜩 기사가 난 걸 고려하면 더 그렇습니다. 그리고 편향이나 차별 같은 문제랑은 또 별개로, 자동 이미지 크롭과 같은 편리한 기능과 유저의 자율성 사이에서 어떤 것을 우선해야 하는가도 논의해볼 만한 주제이고요. 최근에는 트위터가 인수가 될 것인가 말 것인가가 엄청난 화제인데, 만약 끝까지 진행된다면 그 이후에 이런 문제에 대한 방향성은 어떻게 될지도 궁금해지네요.


## 참고한 글들

- [Twitter's Photo-Cropping Algorithm Favors Young, Thin Females](https://www.wired.com/story/twitters-photo-cropping-algorithm-favors-young-thin-females/)  / WIRED
- [Sharing learnings about our image cropping algorithm](https://blog.twitter.com/engineering/en_us/topics/insights/2021/sharing-learnings-about-our-image-cropping-algorithm) / Twitter Engineering Blog
- [Sharing learnings from the first algorithmic bias bounty challenge](https://blog.twitter.com/engineering/en_us/topics/insights/2021/learnings-from-the-first-algorithmic-bias-bounty-challenge) / Twitter Engineering Blog


